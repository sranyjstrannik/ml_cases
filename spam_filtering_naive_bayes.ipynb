{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Наивный байесовский классификатор для фильтрации спама в смс-сообщениях"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import string, re\n",
    "import itertools as it\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.base import TransformerMixin, BaseEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1324 1324\n"
     ]
    }
   ],
   "source": [
    "# читаем данные\n",
    "with open(r'.\\SMSSpamCorpus01\\english_big.txt', encoding='utf-8') as f:\n",
    "    t = f.readlines()\n",
    "    \n",
    "target = [row.split(',')[-1].startswith('spam') for row in t]\n",
    "text = [','.join(row.split(',')[:-1]) for row in t]\n",
    "\n",
    "print(len(text), len(target))\n",
    "\n",
    "train_ratio = 0.9\n",
    "X_train, X_test, y_train, y_test = train_test_split(text, target, train_size=train_ratio, test_size=1-train_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задача фильтрации спама и способ ее решения через формулу Байеса\n",
    "Пусть есть некоторый набор текстов, разбитый на токены. Пусть каждому тексту соответствует вектор $\\vec{x} = (x_1, x_2, x_3, .... x_n)$, где $x_i$ -- количество вхождений $i-го$ токена в текст, $n$ -- количество всех возможных токенов во всех текстах, \"словарь\". Пусть, кроме того, некоторым текстам проставлена метка <спам> или <не спам>, и требуется научиться ставить такие же метки для всех текстов.<br> Предполагается, что признаки $(x_1, x_2, x_3, .... x_n)$ распределены независимо друг от друга. (Из-за этого предположения классификатор и называется **_наивным_**, и, как ни странно, даже если это предположение не выполняется, классификатор, основанный на таком предположении, все равно работает хорошо!). Тогда, если известна каждая из вероятностей *P($\\vec{x}$|спам)*, *P($\\vec{x}$|не спам)*, *P(спам)*, *P(не спам)*,*P($\\vec{x}$)*, каждый новый текст можно однозначно отнести либо к категории <спам>, либо к категории <не спам>, сравнив апостриорные вероятности, высчитанные по правилу Байеса: $$P(спам|\\vec{x}) = \\frac{P(спам) * P(\\vec{x}|спам)}{P(\\vec{x})} \\,\\,\\,\\,[1]$$ и $$P(не\\, спам|\\vec{x}) = \\frac{P(не\\, спам) * P(\\vec{x}|не\\, спам)}{P(\\vec{x})}\\,\\,\\,[2]$$ \n",
    "\n",
    "#### Воплощение в реальность\n",
    "При реализации описанного подхода требуется решить две задачи: <br>1. Выбрать способ токенизации обучающих текстов. Класс CountVectorizer <br> 2. Выбрать способ оценки вероятностей *P($\\vec{x}$|спам)*, *P($\\vec{x}$|не спам)*, *P(спам)*, *P(не спам)*,*P($\\vec{x}$)* в процессе обучения метода. Мы ведь не знаем эти вероятности точно, их требуется получить из размеченных данных. Для этих целей в sklearn есть три класса: BernoulliNB, GaussianNB, MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Признаки из текста можно вытащить тоже несколькими способами, по-разному настраивая CountVectorizer. Он работает следующим образом. При вызове .fit() происходит следующее:\n",
    "    1. Входной текст делится на токены согласно параметру token_pattern\n",
    "    2. Если какие-то из токенов есть в stop_words, они отбрасываются\n",
    "    3. Потом из оставшихся токенов формируются энграммы с длинами, указанными в параметре ngram_range\n",
    "    4. Если энграмма раньше не встречалась в словаре CountVectorizer'а, она добавляется в этот словарь\n",
    "    5. Если частота, с которой энграмма встречается во всех документах, больше max_df или меньше min_df, она отбрасывается \n",
    "    6. Если в словаре в итоге оказывается больше \"слов\", чем указано в max_features, словарь обрезается так, чтобы остались только самые популярные слова\n",
    "Итак, словарь сформирован. Дальше, при вызове .transform(), входной текст преобразуется в разреженную матрицу длиной в словарь, \n",
    "причем сколько раз соответствующая энграмма есть во входном тексте, такое значение будет в матрице на соответствующей этой энграмме месте. \n",
    "**Сведем интересующие нас параметры CountVectorizer в таблицу**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "| Параметр      | возможные значения      | смысл параметра                                                                   | \n",
    "|---------------|-------------------------|-----------------------------------------------------------------------------------|\n",
    "| token_pattern | '(?u)\\\\b\\\\w\\\\w+\\\\b' п.у.| \"нарезает\" входной текст на последовательности от пробела до пробела с длиной > 1 |\n",
    "|               | '(?:(?!\\d)\\w){2,}'      | не учитывает цифры                                                                |\n",
    "|               | '(?:(?!\\d)\\w)+'         | то же, допускает в качестве токенов последовательности длиной 1                   |\n",
    "| ngram_range   | (1, 1) п.у.             |  просто берет все слова, т.н. bag of words-подход                                 |\n",
    "|               | (1, 2)                  |  все слова плюс все сочетания из двух слов                                        |\n",
    "|               | (2, 2)                  |  все сочетания из трех слов                                                       |\n",
    "| stop_words    | None п.у.               | никакие токены не исключаются из входного текста при обработке                    |\n",
    "|               | 'english'               | встроенный словарь английских стоп-слов                                           |\n",
    "|               | stopwords               | стоп-слова библиотеки nltk                                                        |\n",
    "| max_feautures | int, None п.у.          | максимальный возможный размер словаря, можно с ним поиграться                     |\n",
    "| max_df, min_df| 1.0, 0.0  п.у.          | не учитывать токены, частоты которых не попадают в интервал  [min_df, max_df]     | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После того, как мы сопоставили каждому входному тексту вектор токенов $\\vec{x}$, нужно обучить байесовский классификатор, т.е. подобрать ему подходящие оценки вероятностей на основе имеющихся размеченных данных. Пакет sklearn предоставляет несколько классов, и отличаются они только способом оценки вероятностей: <br><br> \n",
    "    **1. BernoulliNB.**  Эта модель предполагает, что каждый токен либо входит в текст, либо не входит, причем количество вхождений не учитывается, но учитывается только сам факт вхождения. Кроме того, она предполагает, что каждый класс (т.е. условная вероятность *P($\\vec{x}$|<метка>)* для всех возможных $\\vec{x}$) распределен по Бернулли, а вероятность *P($\\vec{x}$|спам)* = $\\prod$(вероятность того, что токен i встретится в документе с меткой спам, если $x_i = 1 $) или (вероятность того, что токен i не встретится в документе с меткой спам, если $x_i=0$) <br>\n",
    "    **2. MultinomialNB. ** Тут предполагается, что каждый класс распределен мультиномиально. *P($\\vec{x}$|спам)* = $\\prod$(вероятность того, что токен i встретится в документе с меткой спам $x_i$ раз)<br> \n",
    "    **3.  GaussianNB. **  А тут -- что каждый класс распределен нормально. Этот метод плохо работает с разреженными матрицами, потому что ему для построения оценок требуется много данных, а у нас для каждого входного текста почти все элементы вектора $\\vec{x}$ зануляются. Поэтому этот подход здесь работает плохо, но мы, однако, попробуем применить его из исследовательских соображений.\n",
    "    \n",
    "\n",
    "Сведем настраиваеваемые параметры классификаторов в таблицу. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| параметр  | описание параметра | возможные значения | BernoulliNB | GaussianNB | MultinomialNB |\n",
    "|-----------|--------------------|--------------------|-------------|------------|---------------|\n",
    "| alpha     | сглаживание| 0..1 п.у.    |     +       |     -      |      +        |\n",
    "| binarize  | при каком значении частоты засчитывать слово как встречающееся в тексте                   | None, float, 0 п.у.|     +       |     -      |      -        |\n",
    "| fit_prior | учитывать вероятности классов во входных данных или брать их из равномерного распределения| False, True п.у.   |     +       |     -      |      +        |\n",
    "| class_prior| априорная вероятность каждого из классов | [a, b, c..], None | + | +* | + |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__* Для GaussianNB параметр называется priors__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Посмотрим сперва, какие результаты выдаст GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ToDenseTransformer(TransformerMixin, BaseEstimator):\n",
    "    def transform(self, X, y=None, **fit_params):\n",
    "        return X.todense()\n",
    "\n",
    "    def fit_transform(self, X, y=None, **fit_params):\n",
    "        self.fit(X, y, **fit_params)\n",
    "        return self.transform(X)\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gnb_pipe = Pipeline([('vector', CountVectorizer()),\n",
    "                     ('todense', ToDenseTransformer()), \n",
    "                     ('gnb', GaussianNB())])\n",
    "gnb_params = dict(\n",
    "    vector__token_pattern = [r'(?u)\\b\\w\\w+\\b', r'(?:(?!\\d)\\w){2,}', r'(?:(?!\\d)\\w)+'],\n",
    "    vector__ngram_range = [(1,1), (1,2), (2,2)],\n",
    "    vector__stop_words = [None, 'english'],\n",
    "    vector__max_features = [None],\n",
    "    vector__max_df = (0.5, 0.75, 1.),\n",
    "    vector__min_df = (0.005, 0.01),\n",
    "    gnb__priors = [None] + [[0.243202416918429, 0.756797583081571]]\n",
    ")\n",
    "gnb_search = GridSearchCV(gnb_pipe, param_grid=gnb_params, verbose=1, scoring='f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 216 candidates, totalling 648 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 648 out of 648 | elapsed:  1.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vector', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocess...nizer=None, vocabulary=None)), ('todense', ToDenseTransformer()), ('gnb', GaussianNB(priors=None))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'vector__stop_words': [None, 'english'], 'vector__min_df': (0.005, 0.01), 'vector__max_df': (0.5, 0.75, 1.0), 'vector__token_pattern': ['(?u)\\\\b\\\\w\\\\w+\\\\b', '(?:(?!\\\\d)\\\\w){2,}', '(?:(?!\\\\d)\\\\w)+'], 'gnb__priors': [None, [0.243202416918429, 0.756797583081571]], 'vector__ngram_range': [(1, 1), (1, 2), (2, 2)], 'vector__max_features': [None]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='f1', verbose=1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Pipeline(memory=None,\n",
       "      steps=[('vector', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=0.5, max_features=None, min_df=0.005,\n",
       "         ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
       "         strip_accents=None, token_pattern='(?:(?!\\\\d)\\\\w){2,}',\n",
       "         tokenizer=None, vocabulary=None)), ('todense', ToDenseTransformer()), ('gnb', GaussianNB(priors=None))]),\n",
       " 0.97102640313019861)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb_search.best_estimator_, gnb_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# бернуллиевский наивный баесовский классификатор\n",
    "bnb_pipe = Pipeline([('vector', CountVectorizer()), ('bnb', BernoulliNB())])\n",
    "bnb_params = dict(\n",
    "    vector__token_pattern = [r'(?u)\\b\\w\\w+\\b', r'(?:(?!\\d)\\w){2,}', r'(?:(?!\\d)\\w)+'],\n",
    "    vector__ngram_range = [(1,1), (1,2), (2,2)],\n",
    "    vector__stop_words = [None, 'english', stopwords.words('english')],\n",
    "    vector__max_features = [None] + list(range(1000, 15000, 2000)),\n",
    "    vector__max_df = (0.5, 0.75, 1.),\n",
    "    vector__min_df = (0.005, 0.01),\n",
    "    bnb__binarize = np.arange(0, 0.5, 0.1),\n",
    "    bnb__alpha = [0.5, 1]\n",
    ")\n",
    "bnb_search = GridSearchCV(bnb_pipe, param_grid=bnb_params, verbose=1,n_jobs=4, scoring='f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12960 candidates, totalling 38880 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:   11.1s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:   24.3s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:   42.5s\n",
      "[Parallel(n_jobs=4)]: Done 1242 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=4)]: Done 1792 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=4)]: Done 2442 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=4)]: Done 3192 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=4)]: Done 4042 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=4)]: Done 4992 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=4)]: Done 6042 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=4)]: Done 7192 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=4)]: Done 8442 tasks      | elapsed:  7.0min\n",
      "[Parallel(n_jobs=4)]: Done 9792 tasks      | elapsed:  8.0min\n",
      "[Parallel(n_jobs=4)]: Done 11242 tasks      | elapsed:  9.2min\n",
      "[Parallel(n_jobs=4)]: Done 12792 tasks      | elapsed: 10.3min\n",
      "[Parallel(n_jobs=4)]: Done 14442 tasks      | elapsed: 11.6min\n",
      "[Parallel(n_jobs=4)]: Done 16192 tasks      | elapsed: 12.9min\n",
      "[Parallel(n_jobs=4)]: Done 18042 tasks      | elapsed: 14.4min\n",
      "[Parallel(n_jobs=4)]: Done 19992 tasks      | elapsed: 15.9min\n",
      "[Parallel(n_jobs=4)]: Done 22042 tasks      | elapsed: 17.4min\n",
      "[Parallel(n_jobs=4)]: Done 24192 tasks      | elapsed: 19.1min\n",
      "[Parallel(n_jobs=4)]: Done 26442 tasks      | elapsed: 20.8min\n",
      "[Parallel(n_jobs=4)]: Done 28792 tasks      | elapsed: 22.6min\n",
      "[Parallel(n_jobs=4)]: Done 31242 tasks      | elapsed: 24.7min\n",
      "[Parallel(n_jobs=4)]: Done 33792 tasks      | elapsed: 26.7min\n",
      "[Parallel(n_jobs=4)]: Done 36442 tasks      | elapsed: 28.8min\n",
      "[Parallel(n_jobs=4)]: Done 38880 out of 38880 | elapsed: 30.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 30min 43s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vector', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocess...vocabulary=None)), ('bnb', BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True))]),\n",
       "       fit_params=None, iid=True, n_jobs=4,\n",
       "       param_grid={'vector__stop_words': [None, 'english', ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', ...or__min_df': (0.005, 0.01), 'bnb__alpha': [0.5, 1], 'vector__ngram_range': [(1, 1), (1, 2), (2, 2)]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='f1', verbose=1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "bnb_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# полиномиальный наивный баесовский классификатор\n",
    "mnb_pipe = Pipeline([('vector', CountVectorizer()), ('mnb', MultinomialNB())])\n",
    "mnb_params = dict(\n",
    "    vector__token_pattern = [r'(?u)\\b\\w\\w+\\b', r'(?:(?!\\d)\\w){2,}', r'(?:(?!\\d)\\w)+'],\n",
    "    vector__ngram_range = [(1,1), (1,2), (2,2)],\n",
    "    vector__stop_words = [None, 'english', stopwords.words('english')],\n",
    "    vector__max_features = [None] + list(range(1000, 15000, 2000)),\n",
    "    vector__max_df = (0.5, 0.75, 1.),\n",
    "    vector__min_df = (0.005, 0.01),\n",
    "    mnb__alpha = [0.5, 1]\n",
    ")\n",
    "mnb_search = GridSearchCV(mnb_pipe, param_grid=mnb_params, verbose=1, n_jobs=4, scoring='f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2592 candidates, totalling 7776 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:   10.4s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:   21.8s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:   37.7s\n",
      "[Parallel(n_jobs=4)]: Done 1242 tasks      | elapsed:   58.4s\n",
      "[Parallel(n_jobs=4)]: Done 1792 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=4)]: Done 2442 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=4)]: Done 3192 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=4)]: Done 4042 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=4)]: Done 4992 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=4)]: Done 6042 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=4)]: Done 7192 tasks      | elapsed:  5.5min\n",
      "[Parallel(n_jobs=4)]: Done 7776 out of 7776 | elapsed:  5.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5min 54s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vector', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocess...nizer=None, vocabulary=None)), ('mnb', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       "       fit_params=None, iid=True, n_jobs=4,\n",
       "       param_grid={'vector__stop_words': [None, 'english', ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', ..._min_df': (0.005, 0.01), 'vector__max_features': [None, 1000, 3000, 5000, 7000, 9000, 11000, 13000]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='f1', verbose=1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "mnb_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Pipeline(memory=None,\n",
       "      steps=[('vector', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=0.5, max_features=None, min_df=0.005,\n",
       "         ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "         strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "         tokenizer=None, vocabulary=None)), ('bnb', BernoulliNB(alpha=0.5, binarize=0.0, class_prior=None, fit_prior=True))]),\n",
       " 0.98459731372794024)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnb_search.best_estimator_, bnb_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Pipeline(memory=None,\n",
       "      steps=[('vector', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=0.5, max_features=None, min_df=0.005,\n",
       "         ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
       "         strip_accents=None, token_pattern='(?:(?!\\\\d)\\\\w){2,}',\n",
       "         tokenizer=None, vocabulary=None)), ('mnb', MultinomialNB(alpha=1, class_prior=None, fit_prior=True))]),\n",
       " 0.98147145986341955)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb_search.best_estimator_, mnb_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- multinomial -------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False    0.99065   0.98148   0.98605       108\n",
      "       True    0.92308   0.96000   0.94118        25\n",
      "\n",
      "avg / total    0.97795   0.97744   0.97761       133\n",
      "\n",
      "----------- bernoulli -------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False    0.98165   0.99074   0.98618       108\n",
      "       True    0.95833   0.92000   0.93878        25\n",
      "\n",
      "avg / total    0.97727   0.97744   0.97727       133\n",
      "\n",
      "----------- gaussian -------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False    1.00000   0.96296   0.98113       108\n",
      "       True    0.86207   1.00000   0.92593        25\n",
      "\n",
      "avg / total    0.97407   0.96992   0.97075       133\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# посмотрим теперь на поведение этих классификаторов на отлженной тестовой выборке\n",
    "names = ['multinomial', 'bernoulli', 'gaussian']\n",
    "classifiers = [mnb_search.best_estimator_, bnb_search.best_estimator_, gnb_search.best_estimator_]\n",
    "for n, clf in zip(names, classifiers):\n",
    "    print('-----------', n, '-------------')\n",
    "    print(classification_report(y_test, clf.predict(X_test), digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({False: 1003, True: 82})"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# а теперь попробуем еще и на другом датасете проверить эти фильтры\n",
    "with open(r'.\\SMSSpamCorpus01\\english.txt', encoding='utf-8') as f:\n",
    "    another_text = f.readlines()\n",
    "_X = [''.join(text.split(',')[:-1]) for text in another_text]\n",
    "_y = [text.split(',')[-1]=='spam\\n' for text in another_text]\n",
    "Counter(_y) # как видим, тут уже совсем другое распределение, это может здорово сказаться на надежности классификаторов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- multinomial -------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False    0.99800   0.99402   0.99600      1003\n",
      "       True    0.93023   0.97561   0.95238        82\n",
      "\n",
      "avg / total    0.99288   0.99263   0.99271      1085\n",
      "\n",
      "----------- bernoulli -------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False    0.99701   0.99801   0.99751      1003\n",
      "       True    0.97531   0.96341   0.96933        82\n",
      "\n",
      "avg / total    0.99537   0.99539   0.99538      1085\n",
      "\n",
      "----------- gaussian -------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False    0.99800   0.99402   0.99600      1003\n",
      "       True    0.93023   0.97561   0.95238        82\n",
      "\n",
      "avg / total    0.99288   0.99263   0.99271      1085\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for n, clf in zip(names, classifiers):\n",
    "    print('-----------', n, '-------------')\n",
    "    print(classification_report(_y, clf.predict(_X), digits=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**В худшем случае (бернуллиевский наивный байес) классификатор пропускает 3,3% спама**. Кажется, это вполне неплохо. Удивительно, что цифры для мультиноминального и гауссовского классификаторов получились одинаковые с точностью до 5 знаков после запятой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# попробуем теперь еще на одном датасете\n",
    "with open(r'.\\sms-spam-collection-dataset\\spam.csv') as f:\n",
    "    another_data = f.readlines()[1:]\n",
    "yy = [data.split(',',maxsplit=1)[0]=='spam' for data in another_data]\n",
    "xx = [data.split(',',maxsplit=1)[1] for data in another_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({False: 4827, True: 747})"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(yy) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- multinomial -------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False    0.98970   0.91589   0.95137      4827\n",
      "       True    0.63324   0.93842   0.75620       747\n",
      "\n",
      "avg / total    0.94193   0.91891   0.92521      5574\n",
      "\n",
      "----------- bernoulli -------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False    0.98651   0.96996   0.97817      4827\n",
      "       True    0.82488   0.91432   0.86730       747\n",
      "\n",
      "avg / total    0.96485   0.96250   0.96331      5574\n",
      "\n",
      "----------- gaussian -------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False    0.98736   0.92231   0.95373      4827\n",
      "       True    0.64789   0.92369   0.76159       747\n",
      "\n",
      "avg / total    0.94186   0.92250   0.92798      5574\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for n, clf in zip(names, classifiers):\n",
    "    print('-----------', n, '-------------')\n",
    "    print(classification_report(yy, clf.predict(xx), digits=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Видно, что несмотря на полностью новый набор данных, классификаторы еще неплохо работают,\n",
    "хоть и записывают много лишних сообщений в спам. Но, если в общем, у нас **получилось обучить все три модели с неплохой точностью.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Что еще можно улучшить в моделях или дополнительно поисследовать?\n",
    "1. Cтоит еще раз обучить модели на новых данных, скомбинированных их нескольких датасетов.\n",
    "2. Стоит еще тщательнее подойти к подбору параметров классификаторов, в частности, стоит попробовать более качественно подобрать max_df и min_df для BernoulliNB с MultinomialNB, а для GaussianNB попробовать триграммы. \n",
    "3. Поскольку отношение текстов в категориях разнится от датасета к датасету, стоит попробовать запретить классификаторам использовать чистые вероятности _P(<спам>)_ и _P(<не спам>)_, выставив fit_prior=False и вручную задав class_prior\n",
    "\n",
    "Может быть также, что идея создать универсальный спам-фильтр сама по себе не может быть решена с хорошей точностью, т.к. слишком многое во входящем потоке текстов зависит от природы этих текстов, и универсальный спам-фильтр должен учитывать эту природу, чтобы быть качественным."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
